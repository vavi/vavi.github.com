---
layout: post
title: "Java IO 编程"
description: ""
category: 
tags: [J2SE]
---
io 可以分为 disk io,network io 甚至 memory io.

本文主要是disk io.

## OIO(Old IO)

inputstream/outputstream读写字节,reader/writer读写字符;

同样的字节在不同的编码方式下,可以在编辑器中显示为不同的字符

reader/writer 其实是对inputstream/outputstream的封装.

由于disk io 的读写数据的速度远远低于 cpu 处理数据的速度,所以通常在读写时,上面封装一层 buffered stream/reader/writer.

之所以会出现乱码,大部分时因为互相转换字节,字符时,没有指定正确的编码(通常是使用了默认得编码,比如String.getBytes默认使用JVM的默认编码,J2EE容器如tomcat使用了server.xml的ISO-8859-1的编码).


## NIO(New IO)
nio 的flip方法通常是读取流后,将数据写到buffer中.然后在需要将buffer的数据读出来,供应用程序使用.这个时候就需要先调用flip方法,将limit=position,position=0,mark=-1.

nio的clear方法并没有清除掉原来的buffer中的数据,但是由于其position=0,limit=capacity,mark=-1,这样在读取数据时也不会读取到旧的数据

0 <= mark <=position <=limit<=capacity
mark 提供标记,类似书签功能,方便重读.

所有的缓冲区都具有四个属性来提供关于其所包含的数据元素的信息。它们是： 容量（Capacity） 缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。上界（Limit） 缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。位置（Position） 下一个要被读或写的元素的索引。**位置会自动由相应的get( )和put( )函数更新**。标记（Mark） 一个备忘位置。调用mark( )来设定mark = postion。调用reset( )设定position = mark。标记在设定前是未定义的(undefined)。

我们想把这个缓冲区传递给一个通道，以使内容能被全部写出。**但如果通道现在在缓冲区上执行get()，那么它将从我们刚刚插入的有用数据之外取出未定义数据**。**如果我们将位置值重新设为0，通道就会从正确位置开始获取，但是它是怎样知道何时到达我们所插入数据末端的呢？这就是上界属性被引入的目的。上界属性指明了缓冲区有效内容的末端。**我们需要将上界属性设置为当前位置，然后将位置重置为0。我们可以人工用下面的代码实现： **buffer.limit(buffer.position()).position(0);** 但这种从填充到释放状态的缓冲区翻转是API设计者预先设计好的，他们为我们提供了一个非常便利的函数： **Buffer.flip()**;

Rewind()函数与flip()相似，但不影响上界属性。它只是将位置值设回0。您可以使用rewind()后退，重读已经被翻转的缓冲区中的数据。

compact 函数将当前position和limit之间的元素填充到数组buffer的0到limit-position这个范围内,剩余的buff数组内容不变.limit值修改为和capacity一样大.

slice()创建一个从原始缓冲区的当前位置开始的新缓冲区，并且其容量是原始缓冲区的剩余元素数量（limit-position）。这个新缓冲区与原始缓冲区共享一段数据元素子序列。分割出来的缓冲区也会继承只读和直接属性。

arrayOffset()


从磁盘等设备读出channel的数据,然后写到buffer 中 (channel.read)
http://www.zavakid.com/

为什么buffered会快? nio 面向流,面向块的差别有多大?

传统 Java 平台上的 I/O 抽象工作良好，适应用途广泛。但是当移动大量数据时，这些 I/O 类可伸缩性不强，也没有提供当今大多数操作系统普遍具备的常用 I/O 功能，如文件锁定、非块 I/O、就绪性选择和内存映射

还有一种特殊类型的缓冲区，用于内存映射文件。

Channels 提供了将流和通道之间的互相转换API.

下面节选自<<Java NIO>>,总结得很到位.

然而，在大多数情况下，Java 应用程序并非真的受着 I/O 的束缚。操作系统并非不能快速传送数据，让 Java 有事可做；相反，是 JVM 自身在 I/O 方面效率欠佳。操作系统与 Java 基于流的 I/O模型有些不匹配。操作系统要移动的是大块数据（缓冲区），这往往是在硬件直接存储器存取（DMA）的协助下完成的。而 JVM 的 I/O 类喜欢操作小块数据——单个字节、几行文本。结果，操作系统送来整缓冲区的数据，java.io 的流数据类再花大量时间把它们拆成小块，往往拷贝一个小块就要往返于几层对象。操作系统喜欢整卡车地运来数据，java.io 类则喜欢一铲子一铲子地加工数据。有了 NIO，就可以轻松地把一卡车数据备份到您能直接使用的地方（ByteBuffer 对象）。这并不是说使用传统的 I/O 模型无法移动大量数据——当然可以（现在依然可以）。具体地说，RandomAccessFile 类在这方面的效率就不低，只要坚持使用基于数组的 read( )和 write( )方法。这些方法与底层操作系统调用相当接近，尽管必须保留至少一份缓冲区拷贝。
Java 平台提供了一整套 I/O 隐喻，其抽象程度各有不同。然而，离冰冷的现实越远，要想搞清楚来龙去脉就越难——不管使用哪一种抽象，情况都是如此。JDK 1.4 的 NIO 软件包引入了一套新的抽象用于 I/O 处理。与以往不同的是，新的抽象把重点放在了如何缩短抽象与现实之间的距离上面。
进程执行 I/O 操作，归结起来，也就是向操作系统发出请求，让它要么把缓冲区里的数据**排干（写）**，要么用数据把缓冲区**填满（读）**。进程使用这一机制处理所有数据进出操作。操作系统内部处理这一任务的机制，其复杂程度可能超乎想像，但就概念而言，却非常直白易懂。下图简单描述了数据从外部磁盘向运行中的进程的内存区域移动的过程。进程使用 read()系统调用，要求其缓冲区被填满。内核随即向磁盘控制硬件发出命令，要求其从磁盘读取数据。磁盘控制器把数据直接写入内核内存缓冲区，这一步通过 DMA 完成，无需主 CPU 协助。一旦磁盘控制器把缓冲区装满，内核即把数据从内核空间的临时缓冲区拷贝到进程执行 read( )调用时指定的缓冲区。
(截图14)

当进程请求 I/O 操作的时候，它执行一个系统调用（有时称为陷阱）将控制权移交给内核。C/C++程序员所熟知的底层函数 open( )、read( )、write( )和 close( )要做的无非就是建立和执行适当的**系统调用**。当内核以这种方式被调用，它随即采取任何必要步骤，找到进程所需数据，并把数据传送到用户空间内的指定缓冲区。内核试图对数据进行高速缓存或**预读取**，因此进程所需数据可能已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则进程被挂起，内核着手把数据读进内存。为什么不直接让磁盘控制器把数据送到用户空间的缓冲区呢？这样做有几个问题。首先，硬件通常不能直接访问用户空间 1。其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，内核负责数据的分解、再组合工作，因此充当着中间人的角色。
使用虚拟内存做好处颇多，总结起来可分为两大类：1. 一个以上的虚拟地址可指向同一个物理内存地址。2. 虚拟内存空间可大于实际可用的硬件内存。上文讲到,设备控制器不能通过 DMA 直接存储到用户空间，但通过利用上面提到的第一项，则可以达到相同效果。把内核空间地址与用户空间的虚拟地址映射到同一个物理地址，这样，DMA 硬件（只能访问物理内存地址）就可以填充对内核与用户空间进程同时可见的缓冲区.这样做省去了内核与用户空间的往来拷贝，但前提条件是，内核与用户缓冲区必须使用相同的页对齐，缓冲区的大小还必须是磁盘控制器块大小（通常为 512字节磁盘扇区）的倍数。操作系统把内存地址空间划分为页，即固定大小的字节组。内存页的大小总是磁盘块大小的倍数，通常为 2 次幂（这样可简化寻址操作）。典型的内存页为 1,024、2,048 和 4,096 字节。虚拟和物理内存页的大小总是相同的。
现代 CPU 包含一个称为内存管理单元（MMU）的子系统，逻辑上位于 CPU 与物理内存之间。该设备包含虚拟地址向物理内存地址转换时所需映射信息。当 CPU 引用某内存地址时，MMU负责确定该地址所在页（往往通过对地址值进行移位或屏蔽位操作实现），并将虚拟页号转换为物理页号（这一步由硬件完成，速度极快）。如果当前不存在与该虚拟页形成有效映射的物理内存页，MMU 会向 CPU 提交一个页错误。页错误随即产生一个陷阱（类似于系统调用），把控制权移交给内核，附带导致错误的虚拟地址信息，然后内核采取步骤验证页的有效性。内核会安排页面调入操作，把缺失的页内容读回物理内存。这往往导致别的页被移出物理内存，好给新来的页让地方。在这种情况下，如果待移出的页已经被碰过了（自创建或上次页面调入以来，内容已发生改变），还必须首先执行页面调出，把页内容拷贝到磁盘上的分页区。如果所要求的地址不是有效的虚拟内存地址（不属于正在执行的进程的任何一个内存段），则该页不能通过验证，段错误随即产生。于是，控制权转交给内核的另一部分，通常导致的结果就是进程被强令关闭。一旦出错的页通过了验证，MMU 随即更新，建立新的虚拟到物理的映射（如有必要，中断被移出页的映射），用户进程得以继续。造成页错误的用户进程对此不会有丝毫察觉，一切都在不知不觉中进行。
文件 I/O 属文件系统范畴，文件系统与磁盘迥然不同。磁盘把数据存在扇区上，通常一个扇区512 字节。磁盘属硬件设备，对何谓文件一无所知，它只是提供了一系列数据存取窗口。在这点上，磁盘扇区与内存页颇有相似之处：都是统一大小，都可作为大的数组被访问。文件系统是更高层次的抽象，是安排、解释磁盘（或其他随机存取块设备）数据的一种独特方式。您所写代码几乎无一例外地要与文件系统打交道，而不是直接与磁盘打交道。是文件系统定义了文件名、路径、文件、文件属性等抽象概念。
前文讲到，所有 I/O 都是通过请求页面调度完成的。页面调度是非常底层的操作，仅发生于磁盘扇区与内存页之间的直接传输。而文件 I/O 则可以任意大小、任意定位。那么，底层的页面调度是如何转换为文件 I/O 的？文件系统把一连串大小一致的数据块组织到一起。有些块存储元信息，如空闲块、目录、索引等的映射，有些包含文件数据。单个文件的元信息描述了哪些块包含文件数据、数据在哪里结束、最后一次更新是什么时候，等等。
当用户进程请求读取文件数据时，文件系统需要确定数据具体在磁盘什么位置，然后着手把相关磁盘扇区读进内存。老式的操作系统往往直接向磁盘驱动器发布命令，要求其读取所需磁盘扇区。而采用分页技术的现代操作系统则利用请求页面调度取得所需数据。操作系统还有个页的概念，其大小或者与基本内存页一致，或者是其倍数。典型的操作系统页从 2,048 到 8,192 字节不等，且始终是基本内存页大小的倍数。采用分页技术的操作系统执行 I/O 的全过程可总结为以下几步：• 确定请求的数据分布在文件系统的哪些页（磁盘扇区组）。磁盘上的文件内容和元数据可能跨越多个文件系统页，而且这些页可能也不连续。• 在内核空间分配足够数量的内存页，以容纳得到确定的文件系统页。
在内存页与磁盘上的文件系统页之间建立映射。• 为每一个内存页产生页错误。• 虚拟内存系统俘获页错误，安排页面调入，从磁盘上读取页内容，使页有效。• 一旦页面调入操作完成，文件系统即对原始数据进行解析，取得所需文件内容或属性信息。需要注意的是，这些文件系统数据也会同其他内存页一样得到高速缓存。对于随后发生的 I/O请求，文件数据的部分或全部可能仍旧位于物理内存当中，无需再从磁盘读取即可重复使用。大多数操作系统假设进程会继续读取文件剩余部分，因而会预读额外的文件系统页。如果内存争用情况不严重，这些文件系统页可能在相当长的时间内继续有效。这样的话，当稍后该文件又被相同或不同的进程再次打开，可能根本无需访问磁盘。这种情况您可能也碰到过：当重复执行类似的操作，如在几个文件中进行字符串检索，第二遍运行得似乎快多了。
传统的文件 I/O 是通过用户进程发布 read( )和 write( )系统调用来传输数据的。为了在内核空间的文件系统页与用户空间的内存区之间移动数据，一次以上的拷贝操作几乎总是免不了的。这是因为，在文件系统页与用户缓冲区之间往往没有一一对应关系。但是，还有一种大多数操作系统都支持的特殊类型的 I/O 操作，允许用户进程最大限度地利用面向页的系统 I/O 特性，并完全摒弃缓冲区拷贝。这就是内存映射 I/O
传统的文件 I/O 是通过用户进程发布 read( )和 write( )系统调用来传输数据的。为了在内核空间的文件系统页与用户空间的内存区之间移动数据，一次以上的拷贝操作几乎总是免不了的。这是因为，在文件系统页与用户缓冲区之间往往没有一一对应关系。但是，还有一种大多数操作系统都支持的特殊类型的 I/O 操作，允许用户进程最大限度地利用面向页的系统 I/O 特性，并完全摒弃缓冲区拷贝。这就是内存映射 I/O存。如果用户修改了映射内存空间，相关页会自动标记为脏，随后刷新到磁盘，文件得到更新。• 操作系统的虚拟内存子系统会对页进行智能高速缓存，自动根据系统负载进行内存管理。• 数据总是按页对齐的，无需执行缓冲区拷贝。• 大型文件使用映射，无需耗费大量内存，即可进行数据拷贝。
并非所有 I/O 都像前几节讲的是面向块的，也有流 I/O，其原理模仿了通道。I/O 字节流必须顺序存取，常见的例子有 TTY（控制台）设备、打印机端口和网络连接。流的传输一般（也不必然如此）比块设备慢，经常用于间歇性输入。多数操作系统允许把流置于非块模式，这样，进程可以查看流上是否有输入，即便当时没有也不影响它干别的。这样一种能力使得进程可以在有输入的时候进行处理，输入流闲置的时候执行其他功能。比非块模式再进一步，就是就绪性选择。就绪性选择与非块模式类似（常常就是建立在非块模式之上），但是把查看流是否就绪的任务交给了操作系统。操作系统受命查看一系列流，并提醒进程哪些流已经就绪。这样，仅仅凭借操作系统返回的就绪信息，进程就可以使用相同代码和单一线程，实现多活动流的多路传输。这一技术广泛用于网络服务器领域，用来处理数量庞大的网络连接。就绪性选择在大容量缩放方面是必不可少的。---------------------------------------------------
如果您向一个通道中传递一个非直接ByteBuffer对象用于写入，通道可能会在每次调用中隐含地进行下面的操作： 1.创建一个临时的直接ByteBuffer对象。2.将非直接缓冲区的内容复制到临时缓冲中。3.使用临时缓冲区执行低层次I/O操作。4.临时缓冲区对象离开作用域，并最终成为被回收的无用数据。这可能导致缓冲区在每个I/O上复制并产生大量对象，而这种事都是我们极力避免的。不过，依靠工具，事情可以不这么糟糕。运行时间可能会缓存并重新使用直接缓冲区或者执行其他一些聪明的技巧来提高吞吐量。如果您仅仅为一次使用而创建了一个缓冲区，区别并不是很明显。另一方面，如果您将在一段高性能脚本中重复使用缓冲区，分配直接缓冲区并重新使用它们会使您游刃有余。直接缓冲区时I/O的最佳选择，但可能比创建非直接缓冲区要花费更高的成本。直接缓冲区使用的内存是通过调用本地操作系统方面的代码分配的，绕过了标准JVM堆栈。建立和销毁直接缓冲区会明显比具有堆栈的缓冲区更加破费，这取决于主操作系统以及JVM实现。直接缓冲区的内存区域不受无用存储单元收集支配，因为它们位于标准JVM堆栈之外。

每个非布尔原始数据类型都有一个缓冲区类


##Channel

* FileChannel
* ServerSocketChannel
* SocketChannel
* DatagramChannel
 不能直接创建 FileChannel 对象,后3种 可以通过调用相应里地类方法open进行创建Channel对象
 
 FileChannel对象却只能通过在一个打开的RandomAccessFile、FileInputStream或FileOutputStream对象上调用getChannel( )方法来获取
 
 java.net的socket类也有新的getChannel( )方法。这些方法虽然能返回一个相应的socket通道对象，但它们却并非新通道的来源，RandomAccessFile.getChannel( )方法才是。只有在已经有通道存在的时候，它们才返回与一个socket关联的通道；它们永远不会创建新通道



非阻塞模式的通道永远不会让调用的线程休眠。请求的操作要么立即完成，要么返回一个结果表明未进行任何操作。只有面向流的（stream-oriented）的通道，如sockets和pipes才能使用非阻塞模式。将非阻塞I/O和选择器组合起来可以使您的程序利用多路复用I/O（multiplexed I/O）。

Scatter/Gather是一个简单却强大的概念，它是指在多个缓冲区上实现一个简单的I/O操作。对于一个write操作而言，数据是从几个缓冲区按顺序抽取（称为gather）并沿着通道发送的。缓冲区本身并不需要具备这种gather的能力（通常它们也没有此能力）。该gather过程的效果就好比全部缓冲区的内容被连结起来，并在发送数据前存放到一个大的缓冲区中。对于read操作而言，从通道读取的数据会按顺序被散布（称为scatter）到多个缓冲区，将每个缓冲区填满直至通道中的数据或者缓冲区的最大空间被消耗完。大多数现代操作系统都支持本地矢量I/O（native vectored I/O）。当您在一个通道上请求一个Scatter/Gather操作时，该请求会被翻译为适当的本地调用来直接填充或抽取缓冲区。这是一个很大的进步，因为减少或避免了缓冲区拷贝和系统调用。Scatter/Gather应该使用直接的ByteBuffers以从本地I/O获取最大性能优势。

使用得当的话，Scatter/Gather会是一个极其强大的工具。它允许您委托操作系统来完成辛苦活：将读取到的数据分开存放到多个存储桶（bucket）或者将不同的数据区块合并成一个整体。这是一个巨大的成就，因为操作系统已经被高度优化来完成此类工作了。它节省了您来回移动数据的工作，也就避免了缓冲区拷贝和减少了您需要编写、调试的代码数量。既然您基本上通过提供数据容器引用来组合数据，那么按照不同的组合构建多个缓冲区阵列引用，各种数据区块就可以以不同的方式来组合了。

文件通道总是阻塞式的，因此不能被置于非阻塞模式。现代操作系统都有复杂的缓存和预取机制，使得本地磁盘I/O操作延迟很少。网络文件系统一般而言延迟会多些，不过却也因该优化而受益。面向流的I/O的非阻塞范例对于面向文件的操作并无多大意义，这是由文件I/O本质上的不同性质造成的。对于文件I/O，最强大之处在于异步I/O（asynchronous I/O），它允许一个进程可以从操作系统请求一个或多个I/O操作而不必等待这些操作的完成。发起请求的进程之后会收到它请求的I/O操作已完成的通知。异步I/O是一种高级性能，当前的很多操作系统都还不具备。以后的NIO增强也会把异步I/O纳入考虑范围。

锁与文件关联，而不是与通道关联。我们使用锁来判优外部进程，而不是判优同一个Java虚拟机上的线程。


请注意DatagramChannel和SocketChannel实现定义读和写功能的接口而ServerSocketChannel不实现。ServerSocketChannel负责监听传入的连接和创建新的SocketChannel对象，它本身从不传输数据。在我们具体讨论每一种socket通道前，您应该了解socket和socket通道之间的关系。之前的章节中有写道，通道是一个连接I/O服务导管并提供与该服务交互的方法。就某个socket而言，它不会再次实现与之对应的socket通道类中的socket协议API，而java.net中已经存在的socket通道都可以被大多数协议操作重复使用。全部socket通道类（DatagramChannel、SocketChannel和ServerSocketChannel）在被实例化时都会创建一个对等socket对象。这些是我们所熟悉的来自java.net的类（Socket、ServerSocket和DatagramSocket），它们已经被更新以识别通道。对等socket可以通过调用socket( )方法从一个通道上获取。此外，这三个java.net类现在都有getChannel( )方法。虽然每个socket通道（在java.nio.channels包中）都有一个关联的java.net socket对象，却并非所有的socket都有一个关联的通道。如果您用传统方式（直接实例化）创建了一个Socket对象，它就不会有关联的SocketChannel并且它的getChannel( )方法将总是返回null。Socket通道委派协议操作给对等socket对象。如果在通道类中存在似乎重复的socket方法，那么将有某个新的或者不同的行为同通道类上的这个方法相关联。3.5.1 非阻塞模式Socket通道可以在非阻塞模式下运行。这个陈述虽然简单却有着深远的含义。传统Java socket的阻塞性质曾经是Java程序可伸缩性的最重要制约之一。非阻塞I/O是许多复杂的、高性能的程序构建的基础。要把一个socket通道置于非阻塞模式，我们要依靠所有socket通道类的公有超级类：SelectableChannel。下面的方法就是关于通道的阻塞模式的： public abstract class SelectableChannel extends AbstractChannel implements Channel { // This is a partial API listing public abstract void configureBlocking (boolean block) throws IOException; public abstract
或者无用存储单元收集可能随时对其进行移动 这个翻译的太不专业了
FileChannel类。这个强大的新通道提供了对高级文件操作的访问，以前这是不对Java编程开放的。新的功能特性包括：文件锁定、内存映射文件以及channel-to-channel传输。

#参考
http://ifeve.com/java-nio-all/
http://blog.csdn.net/historyasamirror/article/details/5778378
http://www.ibm.com/developerworks/cn/java/j-lo-javaio/
<<Java NIO>>,概述部分总结的相当精彩,后面有些章节翻译的比较差.

{% include JB/setup %}
